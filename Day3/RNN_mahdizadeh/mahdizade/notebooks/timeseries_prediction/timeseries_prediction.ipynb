{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "import pandas\n",
    "from keras.layers import Dense, LSTM\n",
    "from keras.models import Sequential\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function for Loading Dataset\n",
    "This function use Pandas for loading csv dataset. MinMaxScaler uses for normalizaing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_dataset(datasource):\n",
    "    \"\"\"\n",
    "    The function loads dataset from given file name and uses MinMaxScaler to transform data\n",
    "    :param datasource: file name of data source\n",
    "    :return: tuple of dataset and the used MinMaxScaler\n",
    "    \"\"\"\n",
    "    # load the dataset\n",
    "    dataframe = pandas.read_csv(datasource, usecols=[1])\n",
    "    dataframe = dataframe.fillna(method='pad')\n",
    "    dataset = dataframe.values\n",
    "    dataset = dataset.astype('float32')\n",
    "\n",
    "    plt.plot(dataset)\n",
    "    plt.show()\n",
    "\n",
    "    # normalize the dataset\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    dataset = scaler.fit_transform(dataset)\n",
    "    return dataset, scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function for Creating Dataset\n",
    "This function create training inputs and outputs with look_back parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_dataset(dataset, look_back=1):\n",
    "    \"\"\"\n",
    "    The function takes two arguments: the `dataset`, which is a NumPy array that we want to convert into a dataset,\n",
    "    and the `look_back`, which is the number of previous time steps to use as input variables\n",
    "    to predict the next time period â€” in this case defaulted to 1.\n",
    "    :param dataset: numpy dataset\n",
    "    :param look_back: number of previous time steps as int\n",
    "    :return: tuple of input and output dataset\n",
    "    \"\"\"\n",
    "    data_x, data_y = [], []\n",
    "    for i in range(len(dataset)-look_back-1):\n",
    "        a = dataset[i:(i+look_back), 0]\n",
    "        data_x.append(a)\n",
    "        data_y.append(dataset[i + look_back, 0])\n",
    "    return numpy.array(data_x), numpy.array(data_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function for Spliting Dataset\n",
    "This function split dataset to train and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_dataset(dataset, train_size, look_back):\n",
    "    \"\"\"\n",
    "    Splits dataset into training and test datasets. The last `look_back` rows in train dataset\n",
    "    will be used as `look_back` for the test dataset.\n",
    "    :param dataset: source dataset\n",
    "    :param train_size: specifies the train data size\n",
    "    :param look_back: number of previous time steps as int\n",
    "    :return: tuple of training data and test dataset\n",
    "    \"\"\"\n",
    "    if not train_size > look_back:\n",
    "        raise ValueError('train_size must be lager than look_back')\n",
    "    train, test = dataset[0:train_size, :], dataset[train_size - look_back:len(dataset), :]\n",
    "    print('train_dataset: {}, test_dataset: {}'.format(len(train), len(test)))\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_model(look_back, batch_size=1):\n",
    "    \"\"\"\n",
    "    The function builds a keras Sequential model\n",
    "    :param look_back: number of previous time steps as int\n",
    "    :param batch_size: batch_size as int, defaults to 1\n",
    "    :return: keras Sequential model\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(64,\n",
    "                   activation='relu',\n",
    "                   batch_input_shape=(batch_size, look_back, 1),\n",
    "                   stateful=True,\n",
    "                   return_sequences=False))\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Dataset and Model Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_data(dataset,\n",
    "              look_back,\n",
    "              train_predict,\n",
    "              test_predict,\n",
    "              forecast_predict):\n",
    "    \"\"\"\n",
    "    Plots baseline and predictions.\n",
    "\n",
    "    blue: baseline\n",
    "    green: prediction with training data\n",
    "    red: prediction with test data\n",
    "    cyan: prediction based on predictions\n",
    "\n",
    "    :param dataset: dataset used for predictions\n",
    "    :param look_back: number of previous time steps as int\n",
    "    :param train_predict: predicted values based on training data\n",
    "    :param test_predict: predicted values based on test data\n",
    "    :param forecast_predict: predicted values based on previous predictions\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    plt.plot(dataset)\n",
    "    plt.plot([None for _ in range(look_back)] +\n",
    "             [x for x in train_predict])\n",
    "    plt.plot([None for _ in range(look_back)] +\n",
    "             [None for _ in train_predict] +\n",
    "             [x for x in test_predict])\n",
    "    plt.plot([None for _ in range(look_back)] +\n",
    "             [None for _ in train_predict] +\n",
    "             [None for _ in test_predict] +\n",
    "             [x for x in forecast_predict])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function for forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_forecast(model, look_back_buffer, timesteps=1, batch_size=1):\n",
    "    forecast_predict = numpy.empty((0, 1), dtype=numpy.float32)\n",
    "    for _ in range(timesteps):\n",
    "        # make prediction with current lookback buffer\n",
    "        cur_predict = model.predict(look_back_buffer, batch_size)\n",
    "        # add prediction to result\n",
    "        forecast_predict = numpy.concatenate([forecast_predict, cur_predict], axis=0)\n",
    "        # add new axis to prediction to make it suitable as input\n",
    "        cur_predict = numpy.reshape(cur_predict, (cur_predict.shape[1], cur_predict.shape[0], 1))\n",
    "        # remove oldest prediction from buffer\n",
    "        look_back_buffer = numpy.delete(look_back_buffer, 0, axis=1)\n",
    "        # concat buffer with newest prediction\n",
    "        look_back_buffer = numpy.concatenate([look_back_buffer, cur_predict], axis=1)\n",
    "    return forecast_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nLHES6IUQYomTQC+EEEvc/wMu3j163KHs+AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "datasource = 'international-airline-passengers.csv'\n",
    "dataset, scaler = load_dataset(datasource)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataset: 100, test_dataset: 72\n"
     ]
    }
   ],
   "source": [
    "# split into train and test sets\n",
    "look_back = int(len(dataset) * 0.20)\n",
    "train_size = int(len(dataset) * 0.70)\n",
    "train, test = split_dataset(dataset, train_size, look_back)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Train and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reshape into X=t and Y=t+1\n",
    "train_x, train_y = create_dataset(train, look_back)\n",
    "test_x, test_y = create_dataset(test, look_back)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reshape Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reshape input to be [samples, time steps, features]\n",
    "train_x = numpy.reshape(train_x, (train_x.shape[0], train_x.shape[1], 1))\n",
    "test_x = numpy.reshape(test_x, (test_x.shape[0], test_x.shape[1], 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create and fit model\n",
    "batch_size = 1\n",
    "model = build_model(look_back, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Started!!!\n",
      "Epoch 1/1\n",
      "71/71 [==============================] - 3s 48ms/step - loss: 0.0105\n",
      "Epoch 1/1\n",
      "71/71 [==============================] - 3s 37ms/step - loss: 0.0069\n",
      "Epoch 1/1\n",
      "71/71 [==============================] - 3s 37ms/step - loss: 0.0078\n",
      "Epoch 1/1\n",
      "71/71 [==============================] - 3s 37ms/step - loss: 0.0082\n",
      "Epoch 1/1\n",
      "71/71 [==============================] - 3s 37ms/step - loss: 0.0081\n",
      "Epoch 1/1\n",
      "71/71 [==============================] - 3s 36ms/step - loss: 0.0079\n",
      "Epoch 1/1\n",
      "71/71 [==============================] - 3s 37ms/step - loss: 0.0075\n",
      "Epoch 1/1\n",
      "71/71 [==============================] - 3s 37ms/step - loss: 0.0071\n",
      "Epoch 1/1\n",
      "71/71 [==============================] - 3s 37ms/step - loss: 0.0068\n",
      "Epoch 1/1\n",
      "71/71 [==============================] - 3s 37ms/step - loss: 0.0064\n",
      "Epoch 1/1\n",
      "71/71 [==============================] - 3s 38ms/step - loss: 0.0061\n",
      "Epoch 1/1\n",
      "71/71 [==============================] - 3s 38ms/step - loss: 0.0059\n",
      "Epoch 1/1\n",
      "71/71 [==============================] - 3s 37ms/step - loss: 0.0057\n",
      "Epoch 1/1\n",
      "71/71 [==============================] - 3s 37ms/step - loss: 0.0055\n",
      "Epoch 1/1\n",
      "71/71 [==============================] - 3s 37ms/step - loss: 0.0052\n",
      "Epoch 1/1\n",
      "71/71 [==============================] - 3s 37ms/step - loss: 0.0050\n",
      "Epoch 1/1\n",
      "71/71 [==============================] - 3s 37ms/step - loss: 0.0048\n",
      "Epoch 1/1\n",
      "71/71 [==============================] - 3s 36ms/step - loss: 0.0045\n",
      "Epoch 1/1\n",
      "71/71 [==============================] - 3s 37ms/step - loss: 0.0043\n",
      "Epoch 1/1\n",
      "71/71 [==============================] - 3s 37ms/step - loss: 0.0041\n",
      "Epoch 1/1\n",
      "71/71 [==============================] - 3s 37ms/step - loss: 0.0040\n",
      "Epoch 1/1\n",
      "71/71 [==============================] - 3s 36ms/step - loss: 0.0037\n",
      "Epoch 1/1\n",
      "71/71 [==============================] - 3s 37ms/step - loss: 0.0036\n",
      "Epoch 1/1\n",
      "71/71 [==============================] - 3s 37ms/step - loss: 0.0034\n",
      "Epoch 1/1\n",
      "71/71 [==============================] - 3s 37ms/step - loss: 0.0034\n",
      "Epoch 1/1\n",
      "71/71 [==============================] - 3s 37ms/step - loss: 0.0030\n",
      "Epoch 1/1\n",
      "71/71 [==============================] - 3s 37ms/step - loss: 0.0027\n",
      "Epoch 1/1\n",
      "71/71 [==============================] - 3s 36ms/step - loss: 0.0023\n",
      "Epoch 1/1\n",
      "71/71 [==============================] - 3s 36ms/step - loss: 0.0022\n",
      "Epoch 1/1\n",
      "71/71 [==============================] - 3s 37ms/step - loss: 0.0022\n",
      "Epoch 1/1\n",
      "71/71 [==============================] - 3s 37ms/step - loss: 0.0021\n",
      "Epoch 1/1\n",
      "71/71 [==============================] - 3s 37ms/step - loss: 0.0020\n",
      "Epoch 1/1\n",
      "71/71 [==============================] - 3s 37ms/step - loss: 0.0019\n",
      "Epoch 1/1\n",
      "71/71 [==============================] - 3s 37ms/step - loss: 0.0019\n",
      "Epoch 1/1\n",
      "71/71 [==============================] - 3s 37ms/step - loss: 0.0020\n",
      "Epoch 1/1\n",
      "71/71 [==============================] - 3s 37ms/step - loss: 0.0021\n",
      "Epoch 1/1\n",
      "71/71 [==============================] - 3s 38ms/step - loss: 0.0022\n",
      "Epoch 1/1\n",
      "71/71 [==============================] - 3s 37ms/step - loss: 0.0022\n",
      "Epoch 1/1\n",
      "71/71 [==============================] - 3s 37ms/step - loss: 0.0019\n",
      "Epoch 1/1\n",
      "71/71 [==============================] - 3s 37ms/step - loss: 0.0018\n",
      "Epoch 1/1\n",
      "71/71 [==============================] - 3s 37ms/step - loss: 0.0017\n",
      "Epoch 1/1\n",
      "71/71 [==============================] - 3s 36ms/step - loss: 0.0017\n",
      "Epoch 1/1\n",
      "71/71 [==============================] - 3s 37ms/step - loss: 0.0018\n",
      "Epoch 1/1\n",
      "71/71 [==============================] - 3s 37ms/step - loss: 0.0019\n",
      "Epoch 1/1\n",
      "71/71 [==============================] - 3s 37ms/step - loss: 0.0023\n",
      "Epoch 1/1\n",
      "71/71 [==============================] - 3s 37ms/step - loss: 0.0023\n",
      "Epoch 1/1\n",
      "71/71 [==============================] - 3s 36ms/step - loss: 0.0023\n",
      "Epoch 1/1\n",
      "71/71 [==============================] - 3s 37ms/step - loss: 0.0021\n",
      "Epoch 1/1\n",
      "71/71 [==============================] - 3s 37ms/step - loss: 0.0019\n",
      "Epoch 1/1\n",
      "71/71 [==============================] - 3s 37ms/step - loss: 0.0018\n",
      "Epoch 1/1\n",
      "71/71 [==============================] - 3s 37ms/step - loss: 0.0017\n",
      "Epoch 1/1\n",
      "71/71 [==============================] - 3s 37ms/step - loss: 0.0018\n",
      "Epoch 1/1\n",
      "71/71 [==============================] - 3s 37ms/step - loss: 0.0016\n",
      "Epoch 1/1\n",
      "71/71 [==============================] - 3s 37ms/step - loss: 42755314.3104\n",
      "Epoch 1/1\n",
      "71/71 [==============================] - 3s 37ms/step - loss: 0.0054\n",
      "Epoch 1/1\n",
      "71/71 [==============================] - 3s 36ms/step - loss: 0.0023\n",
      "Epoch 1/1\n",
      "71/71 [==============================] - 3s 37ms/step - loss: 0.0020\n",
      "Epoch 1/1\n",
      "71/71 [==============================] - 3s 38ms/step - loss: 0.0021\n",
      "Epoch 1/1\n",
      "71/71 [==============================] - 3s 37ms/step - loss: 0.0019\n",
      "Epoch 1/1\n",
      "71/71 [==============================] - 3s 37ms/step - loss: 0.0023\n",
      "Epoch 1/1\n",
      "71/71 [==============================] - 3s 37ms/step - loss: 0.0020\n",
      "Epoch 1/1\n",
      "71/71 [==============================] - 3s 37ms/step - loss: 0.0023\n",
      "Epoch 1/1\n",
      "71/71 [==============================] - 3s 37ms/step - loss: 0.0022\n",
      "Epoch 1/1\n",
      "71/71 [==============================] - 3s 37ms/step - loss: 0.0021\n",
      "Epoch 1/1\n",
      "71/71 [==============================] - 3s 38ms/step - loss: 0.0018\n",
      "Epoch 1/1\n",
      "71/71 [==============================] - 3s 37ms/step - loss: 0.0017\n",
      "Epoch 1/1\n",
      "71/71 [==============================] - 3s 37ms/step - loss: 0.0016\n",
      "Epoch 1/1\n",
      "71/71 [==============================] - 3s 37ms/step - loss: 0.0016\n",
      "Epoch 1/1\n",
      "71/71 [==============================] - 3s 37ms/step - loss: 0.0016\n",
      "Epoch 1/1\n",
      "71/71 [==============================] - 3s 37ms/step - loss: 0.0016\n",
      "Epoch 1/1\n",
      "71/71 [==============================] - 3s 37ms/step - loss: 0.0015\n",
      "Epoch 1/1\n",
      "71/71 [==============================] - 3s 36ms/step - loss: 0.0015\n",
      "Epoch 1/1\n",
      "71/71 [==============================] - 3s 37ms/step - loss: 0.0015\n",
      "Epoch 1/1\n",
      "71/71 [==============================] - 3s 37ms/step - loss: 0.0015\n",
      "Epoch 1/1\n",
      "71/71 [==============================] - 3s 38ms/step - loss: 0.0014\n",
      "Epoch 1/1\n",
      "71/71 [==============================] - 3s 37ms/step - loss: 0.0014\n",
      "Epoch 1/1\n",
      "71/71 [==============================] - 3s 37ms/step - loss: 0.0014\n",
      "Epoch 1/1\n",
      "71/71 [==============================] - 3s 37ms/step - loss: 0.0014\n",
      "Epoch 1/1\n",
      "71/71 [==============================] - 3s 36ms/step - loss: 0.0014\n",
      "Epoch 1/1\n",
      "71/71 [==============================] - 3s 37ms/step - loss: 0.0014\n",
      "Epoch 1/1\n",
      "71/71 [==============================] - 3s 37ms/step - loss: 0.0013\n",
      "Epoch 1/1\n",
      "71/71 [==============================] - 3s 36ms/step - loss: 0.0013\n",
      "Epoch 1/1\n",
      "71/71 [==============================] - 3s 37ms/step - loss: 0.0013\n",
      "Epoch 1/1\n",
      "71/71 [==============================] - 3s 37ms/step - loss: 0.0013\n",
      "Epoch 1/1\n",
      "71/71 [==============================] - 3s 37ms/step - loss: 0.0013\n",
      "Epoch 1/1\n",
      "71/71 [==============================] - 3s 37ms/step - loss: 0.0013\n",
      "Epoch 1/1\n",
      "71/71 [==============================] - 3s 36ms/step - loss: 0.0013\n",
      "Epoch 1/1\n",
      "71/71 [==============================] - 3s 36ms/step - loss: 0.0012\n",
      "Epoch 1/1\n",
      "71/71 [==============================] - 3s 37ms/step - loss: 0.0012\n",
      "Epoch 1/1\n",
      "71/71 [==============================] - 3s 37ms/step - loss: 0.0012\n",
      "Epoch 1/1\n",
      "71/71 [==============================] - 3s 36ms/step - loss: 0.0012\n",
      "Epoch 1/1\n",
      "71/71 [==============================] - 3s 36ms/step - loss: 0.0012\n",
      "Epoch 1/1\n",
      "71/71 [==============================] - 3s 37ms/step - loss: 0.0012\n",
      "Epoch 1/1\n",
      "71/71 [==============================] - 3s 37ms/step - loss: 0.0013\n",
      "Epoch 1/1\n",
      "71/71 [==============================] - 3s 36ms/step - loss: 0.0012\n",
      "Epoch 1/1\n",
      "71/71 [==============================] - 3s 36ms/step - loss: 0.0013\n",
      "Epoch 1/1\n",
      "71/71 [==============================] - 3s 37ms/step - loss: 0.0012\n",
      "Epoch 1/1\n",
      "71/71 [==============================] - 3s 37ms/step - loss: 0.0012\n",
      "Epoch 1/1\n",
      "71/71 [==============================] - 3s 37ms/step - loss: 0.0011\n",
      "Epoch 1/1\n",
      "71/71 [==============================] - 3s 37ms/step - loss: 0.0012\n",
      "Train Finished!!!\n"
     ]
    }
   ],
   "source": [
    "print('Train Started!!!')\n",
    "for i in range(100):\n",
    "    model.fit(train_x, train_y, epochs=1, batch_size=batch_size, verbose=1, shuffle=False)\n",
    "    model.reset_states()\n",
    "print('Train Finished!!!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float32').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-b532183c6b72>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mtest_predict_inverse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_predict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mtest_y_inverse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mforecast_predict_inverse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforecast_predict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# calculate root mean squared error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/sklearn/preprocessing/data.py\u001b[0m in \u001b[0;36minverse_transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    381\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'scale_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFLOAT_DTYPES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    451\u001b[0m                              % (array.ndim, estimator_name))\n\u001b[1;32m    452\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 453\u001b[0;31m             \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    454\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m     42\u001b[0m             and not np.isfinite(X).all()):\n\u001b[1;32m     43\u001b[0m         raise ValueError(\"Input contains NaN, infinity\"\n\u001b[0;32m---> 44\u001b[0;31m                          \" or a value too large for %r.\" % X.dtype)\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float32')."
     ]
    }
   ],
   "source": [
    "# generate predictions for training\n",
    "train_predict = model.predict(train_x, batch_size)\n",
    "test_predict = model.predict(test_x, batch_size)\n",
    "\n",
    "# generate forecast predictions\n",
    "forecast_predict = make_forecast(model, test_x[-1::], timesteps=100, batch_size=batch_size)\n",
    "\n",
    "# invert dataset and predictions\n",
    "dataset_inverse = scaler.inverse_transform(dataset)\n",
    "train_predict_inverse = scaler.inverse_transform(train_predict)\n",
    "train_y_inverse = scaler.inverse_transform([train_y])\n",
    "test_predict_inverse = scaler.inverse_transform(test_predict)\n",
    "test_y_inverse = scaler.inverse_transform([test_y])\n",
    "forecast_predict_inverse = scaler.inverse_transform(forecast_predict)\n",
    "\n",
    "# calculate root mean squared error\n",
    "train_score = numpy.sqrt(mean_squared_error(train_y_inverse[0], train_predict_inverse[:, 0]))\n",
    "print('Train Score: %.2f RMSE' % train_score)\n",
    "test_score = numpy.sqrt(mean_squared_error(test_y_inverse[0], test_predict_inverse[:, 0]))\n",
    "print('Test Score: %.2f RMSE' % test_score)\n",
    "\n",
    "plot_data(dataset_inverse, look_back, train_predict_inverse, test_predict_inverse, forecast_predict_inverse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
