{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "'''An implementation of sequence to sequence learning for performing addition\n",
    "\n",
    "Input: \"535+61\"\n",
    "Output: \"596\"\n",
    "Padding is handled by using a repeated sentinel character (space)\n",
    "\n",
    "Input may optionally be reversed, shown to increase performance in many tasks in:\n",
    "\"Learning to Execute\"\n",
    "http://arxiv.org/abs/1410.4615\n",
    "and\n",
    "\"Sequence to Sequence Learning with Neural Networks\"\n",
    "http://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf\n",
    "Theoretically it introduces shorter term dependencies between source and target.\n",
    "\n",
    "Two digits reversed:\n",
    "+ One layer LSTM (128 HN), 5k training examples = 99% train/test accuracy in 55 epochs\n",
    "\n",
    "Three digits reversed:\n",
    "+ One layer LSTM (128 HN), 50k training examples = 99% train/test accuracy in 100 epochs\n",
    "\n",
    "Four digits reversed:\n",
    "+ One layer LSTM (128 HN), 400k training examples = 99% train/test accuracy in 20 epochs\n",
    "\n",
    "Five digits reversed:\n",
    "+ One layer LSTM (128 HN), 550k training examples = 99% train/test accuracy in 30 epochs\n",
    "'''  # noqa\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "from keras import layers\n",
    "from keras.models import Sequential\n",
    "from six.moves import range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Character Encode and Decode Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CharacterTable(object):\n",
    "    \"\"\"Given a set of characters:\n",
    "    + Encode them to a one hot integer representation\n",
    "    + Decode the one hot integer representation to their character output\n",
    "    + Decode a vector of probabilities to their character output\n",
    "    \"\"\"\n",
    "    def __init__(self, chars):\n",
    "        \"\"\"Initialize character table.\n",
    "\n",
    "        # Arguments\n",
    "            chars: Characters that can appear in the input.\n",
    "        \"\"\"\n",
    "        self.chars = sorted(set(chars))\n",
    "        self.char_indices = dict((c, i) for i, c in enumerate(self.chars))\n",
    "        self.indices_char = dict((i, c) for i, c in enumerate(self.chars))\n",
    "\n",
    "    def encode(self, C, num_rows):\n",
    "        \"\"\"One hot encode given string C.\n",
    "\n",
    "        # Arguments\n",
    "            num_rows: Number of rows in the returned one hot encoding. This is\n",
    "                used to keep the # of rows for each data the same.\n",
    "        \"\"\"\n",
    "        x = np.zeros((num_rows, len(self.chars)))\n",
    "        for i, c in enumerate(C):\n",
    "            x[i, self.char_indices[c]] = 1\n",
    "        return x\n",
    "\n",
    "    def decode(self, x, calc_argmax=True):\n",
    "        if calc_argmax:\n",
    "            x = x.argmax(axis=-1)\n",
    "        return ''.join(self.indices_char[x] for x in x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class colors:\n",
    "    ok = '\\033[92m'\n",
    "    fail = '\\033[91m'\n",
    "    close = '\\033[0m'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset and Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters for the model and dataset.\n",
    "TRAINING_SIZE = 50000\n",
    "DIGITS = 3\n",
    "REVERSE = True\n",
    "\n",
    "# Maximum length of input is 'int + int' (e.g., '345+678'). Maximum length of\n",
    "# int is DIGITS.\n",
    "MAXLEN = DIGITS + 1 + DIGITS\n",
    "\n",
    "# All the numbers, plus sign and space for padding.\n",
    "chars = '0123456789+ '\n",
    "ctable = CharacterTable(chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating data...\n",
      "Total addition questions: 50000\n"
     ]
    }
   ],
   "source": [
    "questions = []\n",
    "expected = []\n",
    "seen = set()\n",
    "print('Generating data...')\n",
    "f = lambda: int(''.join(np.random.choice(list('0123456789'))\n",
    "                        for i in range(np.random.randint(1, DIGITS + 1))))\n",
    "while len(questions) < TRAINING_SIZE:\n",
    "    a, b = f(), f()\n",
    "    # Skip any addition questions we've already seen\n",
    "    # Also skip any such that x+Y == Y+x (hence the sorting).\n",
    "    key = tuple(sorted((a, b)))\n",
    "    if key in seen:\n",
    "        continue\n",
    "    seen.add(key)\n",
    "    # Pad the data with spaces such that it is always MAXLEN.\n",
    "    q = '{}+{}'.format(a, b)\n",
    "    query = q + ' ' * (MAXLEN - len(q))\n",
    "    ans = str(a + b)\n",
    "    # Answers can be of maximum size DIGITS + 1.\n",
    "    ans += ' ' * (DIGITS + 1 - len(ans))\n",
    "    if REVERSE:\n",
    "        # Reverse the query, e.g., '12+345  ' becomes '  543+21'. (Note the\n",
    "        # space used for padding.)\n",
    "        query = query[::-1]\n",
    "    questions.append(query)\n",
    "    expected.append(ans)\n",
    "print('Total addition questions:', len(questions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1+551\n"
     ]
    }
   ],
   "source": [
    "print(questions[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorize Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorization...\n"
     ]
    }
   ],
   "source": [
    "print('Vectorization...')\n",
    "x = np.zeros((len(questions), MAXLEN, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(questions), DIGITS + 1, len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(questions):\n",
    "    x[i] = ctable.encode(sentence, MAXLEN)\n",
    "for i, sentence in enumerate(expected):\n",
    "    y[i] = ctable.encode(sentence, DIGITS + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shuffle Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Shuffle (x, y) in unison as the later parts of x will almost all be larger\n",
    "# digits.\n",
    "indices = np.arange(len(y))\n",
    "np.random.shuffle(indices)\n",
    "x = x[indices]\n",
    "y = y[indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Explicitly set apart 10% for validation data that we never train over.\n",
    "split_at = len(x) - len(x) // 10\n",
    "(x_train, x_val) = x[:split_at], x[split_at:]\n",
    "(y_train, y_val) = y[:split_at], y[split_at:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print Dataset Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data:\n",
      "(45000, 7, 12)\n",
      "(45000, 4, 12)\n",
      "Validation Data:\n",
      "(5000, 7, 12)\n",
      "(5000, 4, 12)\n"
     ]
    }
   ],
   "source": [
    "print('Training Data:')\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print('Validation Data:')\n",
    "print(x_val.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 128)               72192     \n",
      "_________________________________________________________________\n",
      "repeat_vector_1 (RepeatVecto (None, 4, 128)            0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 4, 128)            131584    \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 4, 12)             1548      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 4, 12)             0         \n",
      "=================================================================\n",
      "Total params: 205,324\n",
      "Trainable params: 205,324\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Try replacing GRU, or SimpleRNN.\n",
    "RNN = layers.LSTM\n",
    "HIDDEN_SIZE = 128\n",
    "BATCH_SIZE = 128\n",
    "LAYERS = 1\n",
    "\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "# \"Encode\" the input sequence using an RNN, producing an output of HIDDEN_SIZE.\n",
    "# Note: In a situation where your input sequences have a variable length,\n",
    "# use input_shape=(None, num_feature).\n",
    "model.add(RNN(HIDDEN_SIZE, input_shape=(MAXLEN, len(chars))))\n",
    "# As the decoder RNN's input, repeatedly provide with the last hidden state of\n",
    "# RNN for each time step. Repeat 'DIGITS + 1' times as that's the maximum\n",
    "# length of output, e.g., when DIGITS=3, max output is 999+999=1998.\n",
    "model.add(layers.RepeatVector(DIGITS + 1))\n",
    "# The decoder RNN could be multiple layers stacked or a single layer.\n",
    "for _ in range(LAYERS):\n",
    "    # By setting return_sequences to True, return not only the last output but\n",
    "    # all the outputs so far in the form of (num_samples, timesteps,\n",
    "    # output_dim). This is necessary as TimeDistributed in the below expects\n",
    "    # the first dimension to be the timesteps.\n",
    "    model.add(RNN(HIDDEN_SIZE, return_sequences=True))\n",
    "\n",
    "# Apply a dense layer to the every temporal slice of an input. For each of step\n",
    "# of the output sequence, decide which character should be chosen.\n",
    "model.add(layers.TimeDistributed(layers.Dense(len(chars))))\n",
    "model.add(layers.Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Visualization Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 11s 239us/step - loss: 1.8792 - acc: 0.3235 - val_loss: 1.7706 - val_acc: 0.3491\n",
      "Q 52+260  T 312  \u001b[91m☒\u001b[0m 525 \n",
      "Q 457+933 T 1390 \u001b[91m☒\u001b[0m 1155\n",
      "Q 8+902   T 910  \u001b[91m☒\u001b[0m 100 \n",
      "Q 167+57  T 224  \u001b[91m☒\u001b[0m 105 \n",
      "Q 215+87  T 302  \u001b[91m☒\u001b[0m 105 \n",
      "Q 108+55  T 163  \u001b[91m☒\u001b[0m 100 \n",
      "Q 130+278 T 408  \u001b[91m☒\u001b[0m 105 \n",
      "Q 45+620  T 665  \u001b[91m☒\u001b[0m 505 \n",
      "Q 82+986  T 1068 \u001b[91m☒\u001b[0m 100 \n",
      "Q 35+344  T 379  \u001b[91m☒\u001b[0m 555 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 9s 204us/step - loss: 1.7140 - acc: 0.3692 - val_loss: 1.6566 - val_acc: 0.3886\n",
      "Q 689+409 T 1098 \u001b[91m☒\u001b[0m 102 \n",
      "Q 976+14  T 990  \u001b[91m☒\u001b[0m 902 \n",
      "Q 48+911  T 959  \u001b[91m☒\u001b[0m 902 \n",
      "Q 17+424  T 441  \u001b[91m☒\u001b[0m 477 \n",
      "Q 350+92  T 442  \u001b[91m☒\u001b[0m 502 \n",
      "Q 13+875  T 888  \u001b[91m☒\u001b[0m 702 \n",
      "Q 89+152  T 241  \u001b[91m☒\u001b[0m 902 \n",
      "Q 207+31  T 238  \u001b[91m☒\u001b[0m 277 \n",
      "Q 20+343  T 363  \u001b[91m☒\u001b[0m 447 \n",
      "Q 242+62  T 304  \u001b[91m☒\u001b[0m 277 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 3\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 9s 204us/step - loss: 1.5716 - acc: 0.4121 - val_loss: 1.4914 - val_acc: 0.4444\n",
      "Q 431+3   T 434  \u001b[91m☒\u001b[0m 445 \n",
      "Q 798+57  T 855  \u001b[91m☒\u001b[0m 880 \n",
      "Q 243+753 T 996  \u001b[91m☒\u001b[0m 100 \n",
      "Q 107+3   T 110  \u001b[91m☒\u001b[0m 116 \n",
      "Q 86+33   T 119  \u001b[91m☒\u001b[0m 118 \n",
      "Q 74+465  T 539  \u001b[91m☒\u001b[0m 570 \n",
      "Q 38+615  T 653  \u001b[91m☒\u001b[0m 686 \n",
      "Q 15+522  T 537  \u001b[91m☒\u001b[0m 266 \n",
      "Q 576+23  T 599  \u001b[91m☒\u001b[0m 682 \n",
      "Q 68+377  T 445  \u001b[91m☒\u001b[0m 488 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 4\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 9s 205us/step - loss: 1.4190 - acc: 0.4723 - val_loss: 1.3363 - val_acc: 0.5040\n",
      "Q 214+322 T 536  \u001b[91m☒\u001b[0m 667 \n",
      "Q 459+87  T 546  \u001b[91m☒\u001b[0m 550 \n",
      "Q 3+555   T 558  \u001b[91m☒\u001b[0m 555 \n",
      "Q 936+771 T 1707 \u001b[91m☒\u001b[0m 1615\n",
      "Q 80+690  T 770  \u001b[91m☒\u001b[0m 760 \n",
      "Q 431+930 T 1361 \u001b[91m☒\u001b[0m 1310\n",
      "Q 79+789  T 868  \u001b[91m☒\u001b[0m 960 \n",
      "Q 2+965   T 967  \u001b[91m☒\u001b[0m 999 \n",
      "Q 494+1   T 495  \u001b[91m☒\u001b[0m 499 \n",
      "Q 448+671 T 1119 \u001b[91m☒\u001b[0m 1108\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 5\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 9s 201us/step - loss: 1.2763 - acc: 0.5272 - val_loss: 1.2179 - val_acc: 0.5534\n",
      "Q 36+973  T 1009 \u001b[91m☒\u001b[0m 1031\n",
      "Q 85+374  T 459  \u001b[91m☒\u001b[0m 411 \n",
      "Q 236+778 T 1014 \u001b[91m☒\u001b[0m 1001\n",
      "Q 291+9   T 300  \u001b[91m☒\u001b[0m 299 \n",
      "Q 727+533 T 1260 \u001b[91m☒\u001b[0m 1218\n",
      "Q 34+4    T 38   \u001b[91m☒\u001b[0m 44  \n",
      "Q 8+275   T 283  \u001b[91m☒\u001b[0m 285 \n",
      "Q 34+653  T 687  \u001b[91m☒\u001b[0m 691 \n",
      "Q 651+115 T 766  \u001b[91m☒\u001b[0m 771 \n",
      "Q 30+962  T 992  \u001b[91m☒\u001b[0m 101 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 6\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 9s 201us/step - loss: 1.1623 - acc: 0.5735 - val_loss: 1.1056 - val_acc: 0.5991\n",
      "Q 93+726  T 819  \u001b[91m☒\u001b[0m 807 \n",
      "Q 472+289 T 761  \u001b[91m☒\u001b[0m 751 \n",
      "Q 92+468  T 560  \u001b[91m☒\u001b[0m 531 \n",
      "Q 966+623 T 1589 \u001b[91m☒\u001b[0m 1515\n",
      "Q 4+687   T 691  \u001b[91m☒\u001b[0m 685 \n",
      "Q 895+230 T 1125 \u001b[91m☒\u001b[0m 1100\n",
      "Q 623+8   T 631  \u001b[91m☒\u001b[0m 633 \n",
      "Q 823+679 T 1502 \u001b[91m☒\u001b[0m 1570\n",
      "Q 38+43   T 81   \u001b[91m☒\u001b[0m 80  \n",
      "Q 39+674  T 713  \u001b[91m☒\u001b[0m 701 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 7\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 9s 201us/step - loss: 1.0550 - acc: 0.6186 - val_loss: 1.0076 - val_acc: 0.6369\n",
      "Q 371+875 T 1246 \u001b[91m☒\u001b[0m 1225\n",
      "Q 953+49  T 1002 \u001b[91m☒\u001b[0m 1000\n",
      "Q 459+87  T 546  \u001b[91m☒\u001b[0m 553 \n",
      "Q 44+609  T 653  \u001b[91m☒\u001b[0m 655 \n",
      "Q 19+341  T 360  \u001b[91m☒\u001b[0m 362 \n",
      "Q 0+897   T 897  \u001b[91m☒\u001b[0m 998 \n",
      "Q 817+51  T 868  \u001b[91m☒\u001b[0m 874 \n",
      "Q 210+2   T 212  \u001b[92m☑\u001b[0m 212 \n",
      "Q 39+30   T 69   \u001b[91m☒\u001b[0m 77  \n",
      "Q 431+965 T 1396 \u001b[91m☒\u001b[0m 1413\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 8\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 9s 203us/step - loss: 0.9489 - acc: 0.6606 - val_loss: 0.9080 - val_acc: 0.6705\n",
      "Q 882+56  T 938  \u001b[91m☒\u001b[0m 939 \n",
      "Q 642+62  T 704  \u001b[91m☒\u001b[0m 716 \n",
      "Q 207+31  T 238  \u001b[91m☒\u001b[0m 235 \n",
      "Q 548+1   T 549  \u001b[91m☒\u001b[0m 559 \n",
      "Q 525+677 T 1202 \u001b[91m☒\u001b[0m 1100\n",
      "Q 93+68   T 161  \u001b[91m☒\u001b[0m 151 \n",
      "Q 4+465   T 469  \u001b[91m☒\u001b[0m 471 \n",
      "Q 33+799  T 832  \u001b[91m☒\u001b[0m 816 \n",
      "Q 133+342 T 475  \u001b[91m☒\u001b[0m 479 \n",
      "Q 46+49   T 95   \u001b[91m☒\u001b[0m 90  \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 9\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 9s 205us/step - loss: 0.8656 - acc: 0.6919 - val_loss: 0.8373 - val_acc: 0.7016\n",
      "Q 350+464 T 814  \u001b[91m☒\u001b[0m 823 \n",
      "Q 62+728  T 790  \u001b[91m☒\u001b[0m 793 \n",
      "Q 84+95   T 179  \u001b[91m☒\u001b[0m 182 \n",
      "Q 347+431 T 778  \u001b[91m☒\u001b[0m 873 \n",
      "Q 85+334  T 419  \u001b[91m☒\u001b[0m 425 \n",
      "Q 70+410  T 480  \u001b[91m☒\u001b[0m 481 \n",
      "Q 65+153  T 218  \u001b[91m☒\u001b[0m 227 \n",
      "Q 66+264  T 330  \u001b[91m☒\u001b[0m 327 \n",
      "Q 616+97  T 713  \u001b[91m☒\u001b[0m 710 \n",
      "Q 7+685   T 692  \u001b[91m☒\u001b[0m 695 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 10\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 9s 204us/step - loss: 0.7948 - acc: 0.7205 - val_loss: 0.7707 - val_acc: 0.7257\n",
      "Q 54+370  T 424  \u001b[91m☒\u001b[0m 423 \n",
      "Q 350+9   T 359  \u001b[92m☑\u001b[0m 359 \n",
      "Q 352+16  T 368  \u001b[91m☒\u001b[0m 379 \n",
      "Q 53+97   T 150  \u001b[91m☒\u001b[0m 153 \n",
      "Q 285+915 T 1200 \u001b[91m☒\u001b[0m 1199\n",
      "Q 642+62  T 704  \u001b[91m☒\u001b[0m 700 \n",
      "Q 5+227   T 232  \u001b[91m☒\u001b[0m 231 \n",
      "Q 796+90  T 886  \u001b[91m☒\u001b[0m 871 \n",
      "Q 561+97  T 658  \u001b[91m☒\u001b[0m 661 \n",
      "Q 4+972   T 976  \u001b[91m☒\u001b[0m 977 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 11\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 9s 204us/step - loss: 0.7222 - acc: 0.7471 - val_loss: 0.6871 - val_acc: 0.7561\n",
      "Q 553+89  T 642  \u001b[91m☒\u001b[0m 649 \n",
      "Q 730+387 T 1117 \u001b[91m☒\u001b[0m 1116\n",
      "Q 525+43  T 568  \u001b[91m☒\u001b[0m 569 \n",
      "Q 8+221   T 229  \u001b[91m☒\u001b[0m 230 \n",
      "Q 504+48  T 552  \u001b[91m☒\u001b[0m 553 \n",
      "Q 82+556  T 638  \u001b[91m☒\u001b[0m 632 \n",
      "Q 925+22  T 947  \u001b[91m☒\u001b[0m 948 \n",
      "Q 46+643  T 689  \u001b[91m☒\u001b[0m 696 \n",
      "Q 948+386 T 1334 \u001b[91m☒\u001b[0m 1335\n",
      "Q 917+90  T 1007 \u001b[91m☒\u001b[0m 1000\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 12\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 9s 205us/step - loss: 0.6218 - acc: 0.7831 - val_loss: 0.5489 - val_acc: 0.8085\n",
      "Q 850+79  T 929  \u001b[92m☑\u001b[0m 929 \n",
      "Q 34+131  T 165  \u001b[92m☑\u001b[0m 165 \n",
      "Q 294+53  T 347  \u001b[91m☒\u001b[0m 346 \n",
      "Q 143+20  T 163  \u001b[92m☑\u001b[0m 163 \n",
      "Q 79+65   T 144  \u001b[91m☒\u001b[0m 143 \n",
      "Q 747+4   T 751  \u001b[92m☑\u001b[0m 751 \n",
      "Q 46+364  T 410  \u001b[92m☑\u001b[0m 410 \n",
      "Q 613+464 T 1077 \u001b[92m☑\u001b[0m 1077\n",
      "Q 9+183   T 192  \u001b[91m☒\u001b[0m 190 \n",
      "Q 890+79  T 969  \u001b[92m☑\u001b[0m 969 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 13\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 9s 205us/step - loss: 0.4578 - acc: 0.8470 - val_loss: 0.4042 - val_acc: 0.8537\n",
      "Q 52+938  T 990  \u001b[92m☑\u001b[0m 990 \n",
      "Q 3+787   T 790  \u001b[92m☑\u001b[0m 790 \n",
      "Q 91+972  T 1063 \u001b[91m☒\u001b[0m 1073\n",
      "Q 816+222 T 1038 \u001b[91m☒\u001b[0m 1039\n",
      "Q 514+654 T 1168 \u001b[91m☒\u001b[0m 1179\n",
      "Q 720+4   T 724  \u001b[92m☑\u001b[0m 724 \n",
      "Q 572+200 T 772  \u001b[91m☒\u001b[0m 672 \n",
      "Q 782+335 T 1117 \u001b[91m☒\u001b[0m 1128\n",
      "Q 178+36  T 214  \u001b[92m☑\u001b[0m 214 \n",
      "Q 653+214 T 867  \u001b[92m☑\u001b[0m 867 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 14\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 9s 204us/step - loss: 0.3223 - acc: 0.9093 - val_loss: 0.2762 - val_acc: 0.9278\n",
      "Q 74+322  T 396  \u001b[91m☒\u001b[0m 496 \n",
      "Q 78+409  T 487  \u001b[92m☑\u001b[0m 487 \n",
      "Q 35+0    T 35   \u001b[92m☑\u001b[0m 35  \n",
      "Q 92+69   T 161  \u001b[92m☑\u001b[0m 161 \n",
      "Q 22+445  T 467  \u001b[92m☑\u001b[0m 467 \n",
      "Q 121+161 T 282  \u001b[91m☒\u001b[0m 382 \n",
      "Q 28+184  T 212  \u001b[92m☑\u001b[0m 212 \n",
      "Q 7+668   T 675  \u001b[92m☑\u001b[0m 675 \n",
      "Q 27+340  T 367  \u001b[92m☑\u001b[0m 367 \n",
      "Q 24+856  T 880  \u001b[92m☑\u001b[0m 880 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 15\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45000/45000 [==============================] - 9s 207us/step - loss: 0.2324 - acc: 0.9473 - val_loss: 0.2052 - val_acc: 0.9533\n",
      "Q 248+18  T 266  \u001b[92m☑\u001b[0m 266 \n",
      "Q 871+69  T 940  \u001b[91m☒\u001b[0m 930 \n",
      "Q 78+86   T 164  \u001b[91m☒\u001b[0m 165 \n",
      "Q 15+246  T 261  \u001b[92m☑\u001b[0m 261 \n",
      "Q 71+25   T 96   \u001b[92m☑\u001b[0m 96  \n",
      "Q 554+726 T 1280 \u001b[92m☑\u001b[0m 1280\n",
      "Q 153+899 T 1052 \u001b[91m☒\u001b[0m 1053\n",
      "Q 629+19  T 648  \u001b[92m☑\u001b[0m 648 \n",
      "Q 823+679 T 1502 \u001b[92m☑\u001b[0m 1502\n",
      "Q 467+426 T 893  \u001b[92m☑\u001b[0m 893 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 16\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 9s 204us/step - loss: 0.1772 - acc: 0.9635 - val_loss: 0.1516 - val_acc: 0.9722\n",
      "Q 40+52   T 92   \u001b[92m☑\u001b[0m 92  \n",
      "Q 741+175 T 916  \u001b[92m☑\u001b[0m 916 \n",
      "Q 950+31  T 981  \u001b[92m☑\u001b[0m 981 \n",
      "Q 42+60   T 102  \u001b[92m☑\u001b[0m 102 \n",
      "Q 3+859   T 862  \u001b[92m☑\u001b[0m 862 \n",
      "Q 84+567  T 651  \u001b[92m☑\u001b[0m 651 \n",
      "Q 80+715  T 795  \u001b[91m☒\u001b[0m 895 \n",
      "Q 10+87   T 97   \u001b[91m☒\u001b[0m 98  \n",
      "Q 70+29   T 99   \u001b[91m☒\u001b[0m 90  \n",
      "Q 218+41  T 259  \u001b[92m☑\u001b[0m 259 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 17\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 9s 204us/step - loss: 0.1305 - acc: 0.9771 - val_loss: 0.1363 - val_acc: 0.9691\n",
      "Q 394+3   T 397  \u001b[92m☑\u001b[0m 397 \n",
      "Q 588+84  T 672  \u001b[92m☑\u001b[0m 672 \n",
      "Q 26+942  T 968  \u001b[91m☒\u001b[0m 978 \n",
      "Q 94+234  T 328  \u001b[92m☑\u001b[0m 328 \n",
      "Q 99+219  T 318  \u001b[92m☑\u001b[0m 318 \n",
      "Q 71+322  T 393  \u001b[92m☑\u001b[0m 393 \n",
      "Q 35+789  T 824  \u001b[92m☑\u001b[0m 824 \n",
      "Q 446+69  T 515  \u001b[92m☑\u001b[0m 515 \n",
      "Q 825+93  T 918  \u001b[92m☑\u001b[0m 918 \n",
      "Q 852+1   T 853  \u001b[92m☑\u001b[0m 853 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 18\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 9s 206us/step - loss: 0.1116 - acc: 0.9795 - val_loss: 0.0914 - val_acc: 0.9849\n",
      "Q 38+16   T 54   \u001b[92m☑\u001b[0m 54  \n",
      "Q 506+32  T 538  \u001b[92m☑\u001b[0m 538 \n",
      "Q 743+186 T 929  \u001b[91m☒\u001b[0m 939 \n",
      "Q 139+84  T 223  \u001b[92m☑\u001b[0m 223 \n",
      "Q 97+36   T 133  \u001b[92m☑\u001b[0m 133 \n",
      "Q 659+18  T 677  \u001b[92m☑\u001b[0m 677 \n",
      "Q 805+88  T 893  \u001b[92m☑\u001b[0m 893 \n",
      "Q 7+591   T 598  \u001b[92m☑\u001b[0m 598 \n",
      "Q 70+668  T 738  \u001b[92m☑\u001b[0m 738 \n",
      "Q 689+57  T 746  \u001b[92m☑\u001b[0m 746 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 19\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 9s 202us/step - loss: 0.0773 - acc: 0.9893 - val_loss: 0.0839 - val_acc: 0.9842\n",
      "Q 9+106   T 115  \u001b[92m☑\u001b[0m 115 \n",
      "Q 8+569   T 577  \u001b[92m☑\u001b[0m 577 \n",
      "Q 341+571 T 912  \u001b[92m☑\u001b[0m 912 \n",
      "Q 147+1   T 148  \u001b[92m☑\u001b[0m 148 \n",
      "Q 386+4   T 390  \u001b[92m☑\u001b[0m 390 \n",
      "Q 459+938 T 1397 \u001b[92m☑\u001b[0m 1397\n",
      "Q 841+41  T 882  \u001b[92m☑\u001b[0m 882 \n",
      "Q 47+743  T 790  \u001b[92m☑\u001b[0m 790 \n",
      "Q 24+456  T 480  \u001b[92m☑\u001b[0m 480 \n",
      "Q 82+968  T 1050 \u001b[92m☑\u001b[0m 1050\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 20\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 9s 204us/step - loss: 0.0652 - acc: 0.9909 - val_loss: 0.0761 - val_acc: 0.9831\n",
      "Q 819+425 T 1244 \u001b[92m☑\u001b[0m 1244\n",
      "Q 50+99   T 149  \u001b[92m☑\u001b[0m 149 \n",
      "Q 176+21  T 197  \u001b[92m☑\u001b[0m 197 \n",
      "Q 915+188 T 1103 \u001b[92m☑\u001b[0m 1103\n",
      "Q 48+786  T 834  \u001b[92m☑\u001b[0m 834 \n",
      "Q 90+313  T 403  \u001b[92m☑\u001b[0m 403 \n",
      "Q 94+47   T 141  \u001b[92m☑\u001b[0m 141 \n",
      "Q 439+40  T 479  \u001b[92m☑\u001b[0m 479 \n",
      "Q 490+223 T 713  \u001b[92m☑\u001b[0m 713 \n",
      "Q 867+56  T 923  \u001b[92m☑\u001b[0m 923 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 21\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "26496/45000 [================>.............] - ETA: 3s - loss: 0.0541 - acc: 0.9930- ETA: 4s - loss:"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-ca352ab6383f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m               \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m               \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m               validation_data=(x_val, y_val))\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;31m# Select 10 samples from the validation set at random so we can visualize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# errors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2670\u001b[0m                     \u001b[0;34m'In order to feed symbolic tensors to a Keras model '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2671\u001b[0m                     'in TensorFlow, you need tensorflow 1.8 or higher.')\n\u001b[0;32m-> 2672\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2673\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_legacy_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2652\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2653\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2654\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2655\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1140\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1141\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1321\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1310\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1311\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1312\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1418\u001b[0m         return tf_session.TF_Run(\n\u001b[1;32m   1419\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1420\u001b[0;31m             status, run_metadata)\n\u001b[0m\u001b[1;32m   1421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1422\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train the model each generation and show predictions against the validation\n",
    "# dataset.\n",
    "for iteration in range(1, 200):\n",
    "    print()\n",
    "    print('-' * 50)\n",
    "    print('Iteration', iteration)\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=BATCH_SIZE,\n",
    "              epochs=1,\n",
    "              validation_data=(x_val, y_val))\n",
    "    # Select 10 samples from the validation set at random so we can visualize\n",
    "    # errors.\n",
    "    for i in range(10):\n",
    "        ind = np.random.randint(0, len(x_val))\n",
    "        rowx, rowy = x_val[np.array([ind])], y_val[np.array([ind])]\n",
    "        preds = model.predict_classes(rowx, verbose=0)\n",
    "        q = ctable.decode(rowx[0])\n",
    "        correct = ctable.decode(rowy[0])\n",
    "        guess = ctable.decode(preds[0], calc_argmax=False)\n",
    "        print('Q', q[::-1] if REVERSE else q, end=' ')\n",
    "        print('T', correct, end=' ')\n",
    "        if correct == guess:\n",
    "            print(colors.ok + '☑' + colors.close, end=' ')\n",
    "        else:\n",
    "            print(colors.fail + '☒' + colors.close, end=' ')\n",
    "        print(guess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
